{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, Imputer, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate, KFold\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "import joblib\n",
    "import mlflow\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "CURRENT_EXPERIMENT_NAME = 'feature engineering'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 289.19 Mb (53.1% reduction)\n",
      "Mem. usage decreased to 596.49 Mb (53.1% reduction)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.csv', parse_dates=['timestamp']).pipe(reduce_mem_usage)\n",
    "building_metadata = pd.read_csv('data/building_metadata.csv')\n",
    "weather_train = pd.read_csv('data/weather_train.csv', parse_dates=['timestamp'])\n",
    "\n",
    "test = pd.read_csv('data/test.csv', parse_dates=['timestamp']).pipe(reduce_mem_usage)\n",
    "weather_test = pd.read_csv('data/weather_test.csv', parse_dates=['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by(df: pd.DataFrame, **kwargs) -> pd.DataFrame:\n",
    "    df_out = df\n",
    "    for key, value in kwargs.items():\n",
    "        if type(value) is list:\n",
    "            df_out = df_out[df_out[key].isin(value)]\n",
    "        else:\n",
    "            df_out = df_out[df_out[key] == value]\n",
    "    return df_out\n",
    "\n",
    "\n",
    "def missing_rate(df: pd.DataFrame) -> pd.Series:\n",
    "    return df.isnull().sum() / len(df)\n",
    "\n",
    "\n",
    "def reduce_mem_usage(df: pd.DataFrame, verbose: bool = True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / (1024 ** 2)    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(\n",
    "            end_mem, 100 * (start_mem - end_mem) / start_mem)\n",
    "        )\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred) -> float:\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "rmse_score = make_scorer(rmse, greater_is_better=False)\n",
    "\n",
    "\n",
    "def add_key_prefix(d: Dict, prefix = 'best_') -> Dict:\n",
    "    return {prefix + key: value for key, value in d.items()}\n",
    "\n",
    "\n",
    "def df_from_cv_results(d: Dict):\n",
    "    df = pd.DataFrame(d)\n",
    "    score_columns = ['mean_test_score', 'mean_train_score']\n",
    "    param_columns = [c for c in df.columns if c.startswith('param_')]\n",
    "    return pd.concat([\n",
    "        -df.loc[:, score_columns],\n",
    "        df.loc[:, param_columns],\n",
    "    ], axis=1).sort_values(by='mean_test_score')\n",
    "\n",
    "\n",
    "def sample(*args, frac: float = 0.01) -> np.ndarray:\n",
    "    n_rows = args[0].shape[0]\n",
    "    random_index = np.random.choice(n_rows, int(n_rows * frac), replace=False)\n",
    "    gen = (\n",
    "        a[random_index] for a in args\n",
    "    )\n",
    "    if len(args) == 1:\n",
    "        return next(gen)\n",
    "    else:\n",
    "        return gen\n",
    "\n",
    "    \n",
    "class BaseTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, x: pd.DataFrame, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x: pd.DataFrame) -> pd.DataFrame:\n",
    "        return x\n",
    "\n",
    "\n",
    "class ColumnTransformer(BaseTransformer):\n",
    "    \n",
    "    def __init__(self, defs: Dict[str, BaseTransformer]):\n",
    "        self.defs = defs\n",
    "    \n",
    "    def fit(self, x: pd.DataFrame, y: np.ndarray = None):\n",
    "        for col, transformer in self.defs.items():\n",
    "            transformer.fit(x[col], y)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, x: pd.DataFrame) -> pd.DataFrame:\n",
    "        xp = x.copy()\n",
    "        for col, transformer in self.defs.items():\n",
    "            xp[col] = transformer.transform(x[col])\n",
    "        return xp\n",
    "    \n",
    "    def fit_transform(self, x: pd.DataFrame, y: np.ndarray = None) -> pd.DataFrame:\n",
    "        xp = x.copy()\n",
    "        for col, transformer in self.defs.items():\n",
    "            if hasattr(transformer, 'fit_transform'):\n",
    "                xp[col] = transformer.fit_transform(x[col], y)\n",
    "            else:\n",
    "                xp[col] = transformer.fit(x[col], y).transform(x[col])\n",
    "        return xp\n",
    "\n",
    "\n",
    "class WrappedLabelEncoder(BaseTransformer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.le = LabelEncoder()\n",
    "    \n",
    "    def fit(self, x, y = None):\n",
    "        self.le.fit(x)\n",
    "        return self\n",
    "\n",
    "    def transform(self, x):\n",
    "        return self.le.transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherImputer(BaseTransformer):\n",
    "    \n",
    "    def transform(self, w: pd.DataFrame) -> pd.DataFrame:\n",
    "        \n",
    "        # add missing datetime\n",
    "        dt_min, dt_max = w['timestamp'].min(), w['timestamp'].max()\n",
    "        empty_df = pd.DataFrame({'timestamp': pd.date_range(start=dt_min, end=dt_max, freq='H')})\n",
    "        w_out = pd.concat([\n",
    "            ws.merge(\n",
    "                empty_df, on='timestamp', how='outer'\n",
    "            ).sort_values(\n",
    "                by='timestamp'\n",
    "            ).assign(\n",
    "                site_id=site_id\n",
    "            ) for site_id, ws in w.groupby('site_id')\n",
    "        ], ignore_index=True)\n",
    "\n",
    "        # large missing rate columns; fill by -999\n",
    "        w_out['cloud_coverage'] = w_out['cloud_coverage'].fillna(-999).astype(np.int16)\n",
    "\n",
    "        # small missing rate columns; fill by same value forward and backward\n",
    "        w_out = pd.concat([\n",
    "            ws.fillna(method='ffill').fillna(method='bfill') for _, ws in w_out.groupby('site_id')\n",
    "        ], ignore_index=True)\n",
    "\n",
    "        # fill nan by mean over all sites\n",
    "        w_mean = w_out.groupby('timestamp').mean().drop(columns=['site_id']).reset_index()\n",
    "        w_mean = w_out.loc[:, ['site_id', 'timestamp']].merge(w_mean, on='timestamp', how='left')\n",
    "        w_out = w_out.where(~w_out.isnull(), w_mean)\n",
    "\n",
    "        # float -> uint\n",
    "        w_out['site_id'] = w_out['site_id'].astype(np.uint8)\n",
    "\n",
    "        return w_out\n",
    "\n",
    "\n",
    "class WeatherEngineerer(BaseTransformer):\n",
    "    \n",
    "    @staticmethod\n",
    "    def shift_by(wdf: pd.DataFrame, n: int) -> pd.DataFrame:\n",
    "        method = 'bfill' if n > 0 else 'ffill'\n",
    "        return pd.concat([\n",
    "            ws.iloc[:, [2, 4, 8]].shift(n).fillna(method=method) for _, ws in wdf.groupby('site_id')\n",
    "        ], axis=0)\n",
    "    \n",
    "    def weather_weighted_average(self, w: pd.DataFrame, hours: int = 5) -> pd.DataFrame:\n",
    "        ahours = abs(hours)\n",
    "        sign = int(hours / ahours)\n",
    "        w_weighted_average = sum(\n",
    "            [self.shift_by(w, (i+1)*sign) * (ahours-i) for i in range(ahours)]\n",
    "        ) / (np.arange(ahours) + 1).sum()\n",
    "\n",
    "        w_weighted_average.columns = ['{0}_wa{1}'.format(c, hours) for c in w_weighted_average.columns]\n",
    "\n",
    "        return pd.concat([w, w_weighted_average], axis=1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def dwdt(df: pd.DataFrame, base_col: str) -> pd.DataFrame:\n",
    "        df_out = df.copy()\n",
    "        df_out[base_col + '_dt_wa1'] = df[base_col] - df[base_col + '_wa1']\n",
    "        df_out[base_col + '_dt_wa-1'] = df[base_col] - df[base_col + '_wa-1']\n",
    "        df_out[base_col + '_dt_wa5'] = df[base_col] - df[base_col + '_wa5']\n",
    "        df_out[base_col + '_dt_wa-5'] = df[base_col] - df[base_col + '_wa-5']\n",
    "        return df_out\n",
    "    \n",
    "    @staticmethod\n",
    "    def wet(df: pd.DataFrame, suffix: str) -> pd.DataFrame:\n",
    "        df_out = df.copy()\n",
    "        df_out['wet' + suffix] = df['air_temperature' + suffix] - df['dew_temperature' + suffix]\n",
    "        return df_out\n",
    "    \n",
    "    def transform(self, w_in: pd.DataFrame) -> pd.DataFrame:\n",
    "        w = w_in.pipe(self.weather_weighted_average, hours=1) \\\n",
    "            .pipe(self.weather_weighted_average, hours=-1) \\\n",
    "            .pipe(self.weather_weighted_average) \\\n",
    "            .pipe(self.weather_weighted_average, hours=-5)\n",
    "\n",
    "        w = w.pipe(self.dwdt, base_col='air_temperature') \\\n",
    "            .pipe(self.dwdt, base_col='dew_temperature') \\\n",
    "            .pipe(self.dwdt, base_col='wind_speed') \\\n",
    "            .pipe(self.wet, suffix='') \\\n",
    "            .pipe(self.wet, suffix='_wa1') \\\n",
    "            .pipe(self.wet, suffix='_wa-1') \\\n",
    "            .pipe(self.wet, suffix='_wa5') \\\n",
    "            .pipe(self.wet, suffix='_wa-5')\n",
    "\n",
    "        return w\n",
    "\n",
    "\n",
    "\n",
    "class WindDirectionEncoder(BaseTransformer):\n",
    "    \n",
    "    @staticmethod\n",
    "    def _from_degree(degree: int) -> int:\n",
    "        val = int((degree / 22.5) + 0.5)\n",
    "        arr = [i for i in range(0,16)]\n",
    "        return arr[(val % 16)]\n",
    "    \n",
    "    def transform(self, x: pd.Series) -> pd.Series:\n",
    "        return x.apply(self._from_degree)\n",
    "\n",
    "\n",
    "class WindSpeedEncoder(BaseTransformer):\n",
    "    \n",
    "    def transform(self, x: pd.Series) -> pd.Series:\n",
    "        return pd.cut(\n",
    "            x,\n",
    "            bins=[0, 0.3, 1.6, 3.4, 5.5, 8, 10.8, 13.9, 17.2, 20.8, 24.5, 28.5, 33, 1000],\n",
    "            right=False, labels=False,\n",
    "        )\n",
    "\n",
    "    \n",
    "weather_pipeline = Pipeline(steps=[\n",
    "    ('impute_missing_value', WeatherImputer()),\n",
    "    ('feature_engineering', WeatherEngineerer()),\n",
    "    ('label_encode', ColumnTransformer({\n",
    "        'wind_direction': WindDirectionEncoder(),\n",
    "        'wind_speed': WindSpeedEncoder(),\n",
    "        'wind_speed_wa1': WindSpeedEncoder(),\n",
    "        'wind_speed_wa-1': WindSpeedEncoder(),    \n",
    "        'wind_speed_wa5': WindSpeedEncoder(),\n",
    "        'wind_speed_wa-5': WindSpeedEncoder(),    \n",
    "    }))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>cloud_coverage</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>air_temperature_wa1</th>\n",
       "      <th>dew_temperature_wa1</th>\n",
       "      <th>wind_speed_wa1</th>\n",
       "      <th>air_temperature_wa-1</th>\n",
       "      <th>dew_temperature_wa-1</th>\n",
       "      <th>wind_speed_wa-1</th>\n",
       "      <th>air_temperature_wa5</th>\n",
       "      <th>dew_temperature_wa5</th>\n",
       "      <th>wind_speed_wa5</th>\n",
       "      <th>air_temperature_wa-5</th>\n",
       "      <th>dew_temperature_wa-5</th>\n",
       "      <th>wind_speed_wa-5</th>\n",
       "      <th>air_temperature_dt_wa1</th>\n",
       "      <th>air_temperature_dt_wa-1</th>\n",
       "      <th>air_temperature_dt_wa5</th>\n",
       "      <th>air_temperature_dt_wa-5</th>\n",
       "      <th>dew_temperature_dt_wa1</th>\n",
       "      <th>dew_temperature_dt_wa-1</th>\n",
       "      <th>dew_temperature_dt_wa5</th>\n",
       "      <th>dew_temperature_dt_wa-5</th>\n",
       "      <th>wind_speed_dt_wa1</th>\n",
       "      <th>wind_speed_dt_wa-1</th>\n",
       "      <th>wind_speed_dt_wa5</th>\n",
       "      <th>wind_speed_dt_wa-5</th>\n",
       "      <th>wet</th>\n",
       "      <th>wet_wa1</th>\n",
       "      <th>wet_wa-1</th>\n",
       "      <th>wet_wa5</th>\n",
       "      <th>wet_wa-5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1019.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>21.1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.393333</td>\n",
       "      <td>20.74</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.606667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.846667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.653333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>24.4</td>\n",
       "      <td>-999</td>\n",
       "      <td>21.1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1020.2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.8</td>\n",
       "      <td>21.1</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.220000</td>\n",
       "      <td>20.52</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>3.180000</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site_id           timestamp  air_temperature  cloud_coverage  \\\n",
       "0        0 2016-01-01 00:00:00             25.0               6   \n",
       "1        0 2016-01-01 01:00:00             24.4            -999   \n",
       "\n",
       "   dew_temperature  precip_depth_1_hr  sea_level_pressure  wind_direction  \\\n",
       "0             20.0               -1.0              1019.7               0   \n",
       "1             21.1               -1.0              1020.2               3   \n",
       "\n",
       "   wind_speed  air_temperature_wa1  dew_temperature_wa1  wind_speed_wa1  \\\n",
       "0           0                 25.0                 20.0               0   \n",
       "1           1                 25.0                 20.0               0   \n",
       "\n",
       "   air_temperature_wa-1  dew_temperature_wa-1  wind_speed_wa-1  \\\n",
       "0                  24.4                  21.1                1   \n",
       "1                  22.8                  21.1                0   \n",
       "\n",
       "   air_temperature_wa5  dew_temperature_wa5  wind_speed_wa5  \\\n",
       "0                 25.0                 20.0               0   \n",
       "1                 25.0                 20.0               0   \n",
       "\n",
       "   air_temperature_wa-5  dew_temperature_wa-5  wind_speed_wa-5  \\\n",
       "0             22.393333                 20.74                1   \n",
       "1             21.220000                 20.52                1   \n",
       "\n",
       "   air_temperature_dt_wa1  air_temperature_dt_wa-1  air_temperature_dt_wa5  \\\n",
       "0                     0.0                      0.6                     0.0   \n",
       "1                    -0.6                      1.6                    -0.6   \n",
       "\n",
       "   air_temperature_dt_wa-5  dew_temperature_dt_wa1  dew_temperature_dt_wa-1  \\\n",
       "0                 2.606667                     0.0                     -1.1   \n",
       "1                 3.180000                     1.1                      0.0   \n",
       "\n",
       "   dew_temperature_dt_wa5  dew_temperature_dt_wa-5  wind_speed_dt_wa1  \\\n",
       "0                     0.0                    -0.74                0.0   \n",
       "1                     1.1                     0.58                1.5   \n",
       "\n",
       "   wind_speed_dt_wa-1  wind_speed_dt_wa5  wind_speed_dt_wa-5  wet  wet_wa1  \\\n",
       "0                -1.5                0.0           -0.846667  5.0      5.0   \n",
       "1                 1.5                1.5            0.980000  3.3      5.0   \n",
       "\n",
       "   wet_wa-1  wet_wa5  wet_wa-5  \n",
       "0       3.3      5.0  1.653333  \n",
       "1       1.7      5.0  0.700000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_pipeline.fit_transform(weather_train).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Metadata Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildingMetadataEngineerer(BaseTransformer):\n",
    "    \n",
    "    def transform(self, bm_in: pd.DataFrame) -> pd.DataFrame:\n",
    "        bm = bm_in.copy()\n",
    "        bm['log_square_feet'] = np.log(bm['square_feet'])\n",
    "        bm['square_feet_per_floor'] = bm['square_feet'] / bm['floor_count']\n",
    "        bm['log_square_feet_per_floor'] = bm['log_square_feet'] / bm['floor_count']\n",
    "        bm['building_age'] = 2019 - bm['year_built']\n",
    "        bm['square_feet_per_age'] = bm['square_feet'] / bm['building_age']\n",
    "        bm['log_square_feet_per_age'] = bm['log_square_feet'] / bm['building_age']\n",
    "        return bm\n",
    "\n",
    "\n",
    "class BuildingMetadataImputer(BaseTransformer):\n",
    "    \n",
    "    def transform(self, bm: pd.DataFrame) -> pd.DataFrame:\n",
    "        return bm.fillna(-999)\n",
    "\n",
    "\n",
    "building_metadata_pipeline = Pipeline(steps=[\n",
    "    ('label_encode', ColumnTransformer({\n",
    "        'primary_use': WrappedLabelEncoder(),\n",
    "    })),\n",
    "    ('feature_engineering', BuildingMetadataEngineerer()),\n",
    "    ('impute_missing_value', BuildingMetadataImputer()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>building_id</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>floor_count</th>\n",
       "      <th>log_square_feet</th>\n",
       "      <th>square_feet_per_floor</th>\n",
       "      <th>log_square_feet_per_floor</th>\n",
       "      <th>building_age</th>\n",
       "      <th>square_feet_per_age</th>\n",
       "      <th>log_square_feet_per_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7432</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>8.913550</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>675.636364</td>\n",
       "      <td>0.810323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2720</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>7.908387</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>181.333333</td>\n",
       "      <td>0.527226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site_id  building_id  primary_use  square_feet  year_built  floor_count  \\\n",
       "0        0            0            0         7432      2008.0       -999.0   \n",
       "1        0            1            0         2720      2004.0       -999.0   \n",
       "\n",
       "   log_square_feet  square_feet_per_floor  log_square_feet_per_floor  \\\n",
       "0         8.913550                 -999.0                     -999.0   \n",
       "1         7.908387                 -999.0                     -999.0   \n",
       "\n",
       "   building_age  square_feet_per_age  log_square_feet_per_age  \n",
       "0          11.0           675.636364                 0.810323  \n",
       "1          15.0           181.333333                 0.527226  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "building_metadata_pipeline.fit_transform(building_metadata).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildingMetaJoiner(BaseTransformer):\n",
    "    \n",
    "    def __init__(self, bm: pd.DataFrame = None):\n",
    "        self.bm = bm\n",
    "    \n",
    "    def transform(self, x: pd.DataFrame) -> pd.DataFrame:\n",
    "        if self.bm is None:\n",
    "            return x\n",
    "        else:\n",
    "            return x.merge(\n",
    "                self.bm,\n",
    "                on='building_id',\n",
    "                how='left',\n",
    "            )\n",
    "\n",
    "    \n",
    "class WeatherJoiner(BaseTransformer):\n",
    "    \n",
    "    def __init__(self, w: pd.DataFrame = None):\n",
    "        self.w = w\n",
    "    \n",
    "    def transform(self, x: pd.DataFrame) -> pd.DataFrame:\n",
    "        if self.w is None:\n",
    "            return x\n",
    "        else:\n",
    "            return x.merge(\n",
    "                self.w,\n",
    "                on=['site_id', 'timestamp'],\n",
    "                how='left',\n",
    "            )\n",
    "\n",
    "\n",
    "class DatetimeFeatureEngineerer(BaseTransformer):\n",
    "    \n",
    "    def __init__(self, col: str = 'timestamp'):\n",
    "        self.col = col\n",
    "    \n",
    "    def transform(self, x: pd.DataFrame) -> pd.DataFrame:\n",
    "        xp = x.copy()\n",
    "        ts = x[self.col]\n",
    "        xp['month'] = ts.dt.month.astype(np.int8)\n",
    "        xp['week'] = ts.dt.week.astype(np.int8)\n",
    "        xp['day_of_week'] = ts.dt.weekday.astype(np.int8)\n",
    "        xp['time_period'] = pd.cut(\n",
    "            ts.dt.hour,\n",
    "            bins=[0, 3, 6, 9, 12, 15, 18, 21, 25],\n",
    "            right=False, labels=False,\n",
    "        )\n",
    "        \n",
    "        holidays = [\n",
    "            '2016-01-01', '2016-01-18', '2016-02-15', '2016-05-30', '2016-07-04',\n",
    "            '2016-09-05', '2016-10-10', '2016-11-11', '2016-11-24', '2016-12-26',\n",
    "            '2017-01-01', '2017-01-16', '2017-02-20', '2017-05-29', '2017-07-04',\n",
    "            '2017-09-04', '2017-10-09', '2017-11-10', '2017-11-23', '2017-12-25',\n",
    "            '2018-01-01', '2018-01-15', '2018-02-19', '2018-05-28', '2018-07-04',\n",
    "            '2018-09-03', '2018-10-08', '2018-11-12', '2018-11-22', '2018-12-25',\n",
    "            '2019-01-01'\n",
    "        ]\n",
    "        xp['is_holiday'] = (ts.dt.date.astype('str').isin(holidays)).astype(np.int8)\n",
    "        return xp\n",
    "\n",
    "\n",
    "class TargetEncoder(BaseTransformer):\n",
    "    \n",
    "    def __init__(self, cv: int = 5, smoothing: int = 1):\n",
    "        self.agg = None\n",
    "        self.cv = cv\n",
    "        self.smoothing = 1\n",
    "    \n",
    "    def transform(self, x: pd.Series):        \n",
    "        if self.agg is None:\n",
    "            raise ValueError('you shold fit() before predict()')\n",
    "        encoded = pd.merge(x, self.agg, left_on=x.name, right_index=True, how='left')\n",
    "        encoded = encoded.fillna(encoded.mean())\n",
    "        xp = encoded['y']\n",
    "        xp.name = x.name\n",
    "        return xp\n",
    "    \n",
    "    def fit_transform(self, x: pd.Series, y: np.ndarray = None) -> pd.Series:\n",
    "        df = pd.DataFrame({'x': x, 'y': y})\n",
    "        self.agg = df.groupby('x').mean()\n",
    "        fold = KFold(n_splits=self.cv, shuffle=True)\n",
    "        xp = x.copy()\n",
    "        for idx_train, idx_test in fold.split(x):\n",
    "            df_train = df.loc[idx_train, :]\n",
    "            df_test = df.loc[idx_test, :]\n",
    "            agg_train = df_train.groupby('x').mean()\n",
    "            encoded = pd.merge(df_test, agg_train, left_on='x', right_index=True, how='left', suffixes=('', '_mean'))['y_mean']\n",
    "            encoded = encoded.fillna(encoded.mean())\n",
    "            xp[encoded.index] = encoded\n",
    "        return xp\n",
    "\n",
    "\n",
    "class ColumnDropper(BaseTransformer):\n",
    "    \n",
    "    def __init__(self, cols: List[str]):\n",
    "        self.cols = cols\n",
    "    \n",
    "    def transform(self, x: pd.DataFrame, y = None) -> pd.DataFrame:\n",
    "        return x.drop(columns=self.cols)\n",
    "\n",
    "\n",
    "class ArrayTransformer(BaseTransformer):\n",
    "    \n",
    "    def transform(self, x: pd.DataFrame, y = None) -> np.ndarray:\n",
    "        return x.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_factory() -> Pipeline:\n",
    "    return Pipeline(steps=[\n",
    "\n",
    "        # join\n",
    "        ('join_building_meta', BuildingMetaJoiner(\n",
    "            building_metadata_pipeline.fit_transform(\n",
    "                building_metadata\n",
    "            )\n",
    "        )),\n",
    "        ('join_weather', WeatherJoiner(\n",
    "            weather_pipeline.fit_transform(\n",
    "                pd.concat([weather_train, weather_test], axis=0, ignore_index=True)\n",
    "            )\n",
    "        )),\n",
    "\n",
    "        # feature engineering\n",
    "        ('feature_engineering_from_datetime', DatetimeFeatureEngineerer()),\n",
    "        ('target_encode', ColumnTransformer({\n",
    "            'primary_use': TargetEncoder(),\n",
    "            'meter': TargetEncoder(),\n",
    "            'cloud_coverage': TargetEncoder(),\n",
    "            'time_period': TargetEncoder(),\n",
    "            'wind_direction': TargetEncoder(),\n",
    "            'wind_speed': TargetEncoder(),\n",
    "            'wind_speed_wa1': TargetEncoder(),\n",
    "            'wind_speed_wa-1': TargetEncoder(),\n",
    "            'wind_speed_wa5': TargetEncoder(),\n",
    "            'wind_speed_wa-5': TargetEncoder(),\n",
    "        })),\n",
    "\n",
    "        # drop columns\n",
    "        ('drop_columns', ColumnDropper([\n",
    "            'building_id', 'timestamp', 'site_id', 'precip_depth_1_hr',\n",
    "        ])),\n",
    "\n",
    "        # pd.DataFrame -> np.ndarray\n",
    "        ('df_to_array', ArrayTransformer()),\n",
    "\n",
    "        # regressor\n",
    "        ('regressor', RandomForestRegressor()),\n",
    "\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>floor_count</th>\n",
       "      <th>log_square_feet</th>\n",
       "      <th>square_feet_per_floor</th>\n",
       "      <th>log_square_feet_per_floor</th>\n",
       "      <th>building_age</th>\n",
       "      <th>square_feet_per_age</th>\n",
       "      <th>log_square_feet_per_age</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>cloud_coverage</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>air_temperature_wa1</th>\n",
       "      <th>dew_temperature_wa1</th>\n",
       "      <th>wind_speed_wa1</th>\n",
       "      <th>air_temperature_wa-1</th>\n",
       "      <th>dew_temperature_wa-1</th>\n",
       "      <th>wind_speed_wa-1</th>\n",
       "      <th>air_temperature_wa5</th>\n",
       "      <th>dew_temperature_wa5</th>\n",
       "      <th>wind_speed_wa5</th>\n",
       "      <th>air_temperature_wa-5</th>\n",
       "      <th>dew_temperature_wa-5</th>\n",
       "      <th>wind_speed_wa-5</th>\n",
       "      <th>air_temperature_dt_wa1</th>\n",
       "      <th>air_temperature_dt_wa-1</th>\n",
       "      <th>air_temperature_dt_wa5</th>\n",
       "      <th>air_temperature_dt_wa-5</th>\n",
       "      <th>dew_temperature_dt_wa1</th>\n",
       "      <th>dew_temperature_dt_wa-1</th>\n",
       "      <th>dew_temperature_dt_wa5</th>\n",
       "      <th>dew_temperature_dt_wa-5</th>\n",
       "      <th>wind_speed_dt_wa1</th>\n",
       "      <th>wind_speed_dt_wa-1</th>\n",
       "      <th>wind_speed_dt_wa5</th>\n",
       "      <th>wind_speed_dt_wa-5</th>\n",
       "      <th>wet</th>\n",
       "      <th>wet_wa1</th>\n",
       "      <th>wet_wa-1</th>\n",
       "      <th>wet_wa5</th>\n",
       "      <th>wet_wa-5</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>time_period</th>\n",
       "      <th>is_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.977547</td>\n",
       "      <td>4.378613</td>\n",
       "      <td>7432</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>8.913550</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>675.636364</td>\n",
       "      <td>0.810323</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.946816</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1019.7</td>\n",
       "      <td>4.240219</td>\n",
       "      <td>4.256431</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.266833</td>\n",
       "      <td>24.4</td>\n",
       "      <td>21.1</td>\n",
       "      <td>4.215470</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.388631</td>\n",
       "      <td>22.393333</td>\n",
       "      <td>20.74</td>\n",
       "      <td>4.235644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.606667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.846667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.653333</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>3.974585</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.977265</td>\n",
       "      <td>4.377218</td>\n",
       "      <td>2720</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>7.908387</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>181.333333</td>\n",
       "      <td>0.527226</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.946735</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1019.7</td>\n",
       "      <td>4.239469</td>\n",
       "      <td>4.255570</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.266833</td>\n",
       "      <td>24.4</td>\n",
       "      <td>21.1</td>\n",
       "      <td>4.215470</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.386168</td>\n",
       "      <td>22.393333</td>\n",
       "      <td>20.74</td>\n",
       "      <td>4.234467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.606667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.846667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.653333</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>3.974208</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.977594</td>\n",
       "      <td>4.377218</td>\n",
       "      <td>5376</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>8.589700</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>0.306775</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.948361</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1019.7</td>\n",
       "      <td>4.240450</td>\n",
       "      <td>4.257884</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.266833</td>\n",
       "      <td>24.4</td>\n",
       "      <td>21.1</td>\n",
       "      <td>4.215470</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.386168</td>\n",
       "      <td>22.393333</td>\n",
       "      <td>20.74</td>\n",
       "      <td>4.235644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.606667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.846667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.653333</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>3.974585</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.977547</td>\n",
       "      <td>4.377971</td>\n",
       "      <td>23685</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>10.072597</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1393.235294</td>\n",
       "      <td>0.592506</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.946735</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1019.7</td>\n",
       "      <td>4.240450</td>\n",
       "      <td>4.255570</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.267848</td>\n",
       "      <td>24.4</td>\n",
       "      <td>21.1</td>\n",
       "      <td>4.215330</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.386009</td>\n",
       "      <td>22.393333</td>\n",
       "      <td>20.74</td>\n",
       "      <td>4.235818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.606667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.846667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.653333</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>3.974585</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.977594</td>\n",
       "      <td>4.377481</td>\n",
       "      <td>116607</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>11.666565</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2650.159091</td>\n",
       "      <td>0.265149</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.946816</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1019.7</td>\n",
       "      <td>4.239469</td>\n",
       "      <td>4.255824</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.266833</td>\n",
       "      <td>24.4</td>\n",
       "      <td>21.1</td>\n",
       "      <td>4.216026</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.386009</td>\n",
       "      <td>22.393333</td>\n",
       "      <td>20.74</td>\n",
       "      <td>4.236122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.606667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.846667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.653333</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>3.974208</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      meter  primary_use  square_feet  year_built  floor_count  \\\n",
       "0  3.977547     4.378613         7432      2008.0       -999.0   \n",
       "1  3.977265     4.377218         2720      2004.0       -999.0   \n",
       "2  3.977594     4.377218         5376      1991.0       -999.0   \n",
       "3  3.977547     4.377971        23685      2002.0       -999.0   \n",
       "4  3.977594     4.377481       116607      1975.0       -999.0   \n",
       "\n",
       "   log_square_feet  square_feet_per_floor  log_square_feet_per_floor  \\\n",
       "0         8.913550                 -999.0                     -999.0   \n",
       "1         7.908387                 -999.0                     -999.0   \n",
       "2         8.589700                 -999.0                     -999.0   \n",
       "3        10.072597                 -999.0                     -999.0   \n",
       "4        11.666565                 -999.0                     -999.0   \n",
       "\n",
       "   building_age  square_feet_per_age  log_square_feet_per_age  \\\n",
       "0          11.0           675.636364                 0.810323   \n",
       "1          15.0           181.333333                 0.527226   \n",
       "2          28.0           192.000000                 0.306775   \n",
       "3          17.0          1393.235294                 0.592506   \n",
       "4          44.0          2650.159091                 0.265149   \n",
       "\n",
       "   air_temperature  cloud_coverage  dew_temperature  sea_level_pressure  \\\n",
       "0             25.0        3.946816             20.0              1019.7   \n",
       "1             25.0        3.946735             20.0              1019.7   \n",
       "2             25.0        3.948361             20.0              1019.7   \n",
       "3             25.0        3.946735             20.0              1019.7   \n",
       "4             25.0        3.946816             20.0              1019.7   \n",
       "\n",
       "   wind_direction  wind_speed  air_temperature_wa1  dew_temperature_wa1  \\\n",
       "0        4.240219    4.256431                 25.0                 20.0   \n",
       "1        4.239469    4.255570                 25.0                 20.0   \n",
       "2        4.240450    4.257884                 25.0                 20.0   \n",
       "3        4.240450    4.255570                 25.0                 20.0   \n",
       "4        4.239469    4.255824                 25.0                 20.0   \n",
       "\n",
       "   wind_speed_wa1  air_temperature_wa-1  dew_temperature_wa-1  \\\n",
       "0        4.266833                  24.4                  21.1   \n",
       "1        4.266833                  24.4                  21.1   \n",
       "2        4.266833                  24.4                  21.1   \n",
       "3        4.267848                  24.4                  21.1   \n",
       "4        4.266833                  24.4                  21.1   \n",
       "\n",
       "   wind_speed_wa-1  air_temperature_wa5  dew_temperature_wa5  wind_speed_wa5  \\\n",
       "0         4.215470                 25.0                 20.0        4.388631   \n",
       "1         4.215470                 25.0                 20.0        4.386168   \n",
       "2         4.215470                 25.0                 20.0        4.386168   \n",
       "3         4.215330                 25.0                 20.0        4.386009   \n",
       "4         4.216026                 25.0                 20.0        4.386009   \n",
       "\n",
       "   air_temperature_wa-5  dew_temperature_wa-5  wind_speed_wa-5  \\\n",
       "0             22.393333                 20.74         4.235644   \n",
       "1             22.393333                 20.74         4.234467   \n",
       "2             22.393333                 20.74         4.235644   \n",
       "3             22.393333                 20.74         4.235818   \n",
       "4             22.393333                 20.74         4.236122   \n",
       "\n",
       "   air_temperature_dt_wa1  air_temperature_dt_wa-1  air_temperature_dt_wa5  \\\n",
       "0                     0.0                      0.6                     0.0   \n",
       "1                     0.0                      0.6                     0.0   \n",
       "2                     0.0                      0.6                     0.0   \n",
       "3                     0.0                      0.6                     0.0   \n",
       "4                     0.0                      0.6                     0.0   \n",
       "\n",
       "   air_temperature_dt_wa-5  dew_temperature_dt_wa1  dew_temperature_dt_wa-1  \\\n",
       "0                 2.606667                     0.0                     -1.1   \n",
       "1                 2.606667                     0.0                     -1.1   \n",
       "2                 2.606667                     0.0                     -1.1   \n",
       "3                 2.606667                     0.0                     -1.1   \n",
       "4                 2.606667                     0.0                     -1.1   \n",
       "\n",
       "   dew_temperature_dt_wa5  dew_temperature_dt_wa-5  wind_speed_dt_wa1  \\\n",
       "0                     0.0                    -0.74                0.0   \n",
       "1                     0.0                    -0.74                0.0   \n",
       "2                     0.0                    -0.74                0.0   \n",
       "3                     0.0                    -0.74                0.0   \n",
       "4                     0.0                    -0.74                0.0   \n",
       "\n",
       "   wind_speed_dt_wa-1  wind_speed_dt_wa5  wind_speed_dt_wa-5  wet  wet_wa1  \\\n",
       "0                -1.5                0.0           -0.846667  5.0      5.0   \n",
       "1                -1.5                0.0           -0.846667  5.0      5.0   \n",
       "2                -1.5                0.0           -0.846667  5.0      5.0   \n",
       "3                -1.5                0.0           -0.846667  5.0      5.0   \n",
       "4                -1.5                0.0           -0.846667  5.0      5.0   \n",
       "\n",
       "   wet_wa-1  wet_wa5  wet_wa-5  month  week  day_of_week  time_period  \\\n",
       "0       3.3      5.0  1.653333      1    53            4     3.974585   \n",
       "1       3.3      5.0  1.653333      1    53            4     3.974208   \n",
       "2       3.3      5.0  1.653333      1    53            4     3.974585   \n",
       "3       3.3      5.0  1.653333      1    53            4     3.974585   \n",
       "4       3.3      5.0  1.653333      1    53            4     3.974208   \n",
       "\n",
       "   is_holiday  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_factory().fit_transform(\n",
    "    train.drop(columns='meter_reading'),\n",
    "    np.log1p(train['meter_reading'].values)\n",
    ").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(pipeline: Pipeline, df: pd.DataFrame, n_jobs: int = -1, **params) -> Tuple[float, float]:\n",
    "    \n",
    "    x = df.drop(columns='meter_reading')\n",
    "    y = np.log1p(df['meter_reading'].values)\n",
    "\n",
    "    default_params = dict(\n",
    "        n_estimators=10,\n",
    "        max_depth=None,\n",
    "        max_features='auto',\n",
    "        min_samples_leaf=1,\n",
    "    )\n",
    "    merged_params = {**default_params, **params}\n",
    "\n",
    "    pipeline_params = {**merged_params, 'n_jobs': n_jobs}\n",
    "    pipeline_params = add_key_prefix(pipeline_params, 'regressor__')\n",
    "    pipeline.set_params(**pipeline_params)\n",
    "    \n",
    "    mlflow.set_experiment(CURRENT_EXPERIMENT_NAME)\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        mlflow.log_params(merged_params)\n",
    "        scores = cross_validate(\n",
    "            pipeline, x, y,\n",
    "            cv=3,\n",
    "            scoring=rmse_score,\n",
    "            return_train_score=True,\n",
    "            verbose=2,\n",
    "        )\n",
    "        \n",
    "        rmse_val = - np.mean(scores['test_score'])\n",
    "        rmse_train = - np.mean(scores['train_score'])\n",
    "        mlflow.log_metrics(dict(\n",
    "            rmse_val=rmse_val,\n",
    "            rmse_train=rmse_train,\n",
    "        ))\n",
    "        return rmse_val, rmse_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv(\n",
    "    pipeline_factory(),\n",
    "    train,\n",
    "    n_jobs=-1,\n",
    "    n_estimators=64,\n",
    "    min_samples_leaf=0.00001,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneshot(pipeline: Pipeline, df: pd.DataFrame, **params):\n",
    "    \n",
    "    x = df.drop(columns='meter_reading')\n",
    "    y = np.log1p(df['meter_reading'].values)\n",
    "\n",
    "    default_params = dict(\n",
    "        n_estimators=10,\n",
    "        max_depth=None,\n",
    "        max_features='auto',\n",
    "        min_samples_leaf=1,\n",
    "    )\n",
    "    merged_params = {**default_params, **params}\n",
    "\n",
    "    pipeline_params = {**merged_params, 'n_jobs': -1, 'verbose': 2}\n",
    "    pipeline_params = add_key_prefix(pipeline_params, 'regressor__')\n",
    "    pipeline.set_params(**pipeline_params)\n",
    "\n",
    "    mlflow.set_experiment(CURRENT_EXPERIMENT_NAME)\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        mlflow.log_params(merged_params)\n",
    "\n",
    "        pipeline.fit(x, y)\n",
    "        joblib.dump(pipeline, 'out/pipeline.sav', compress=1)\n",
    "        \n",
    "        score = rmse(y, pipeline.predict(x))\n",
    "        \n",
    "        mlflow.log_metrics(dict(rmse_train=score))\n",
    "        mlflow.log_artifact('out/pipeline.sav')\n",
    "        \n",
    "        return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = oneshot(pipeline_factory(), train, n_estimators=64, min_samples_leaf=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(pipeline: Pipeline, df: pd.DataFrame, n_jobs: int = -1, **param_grid):\n",
    "            \n",
    "    x = df.drop(columns='meter_reading')\n",
    "    y = np.log1p(df['meter_reading'].values)\n",
    "\n",
    "    default_param_grid = dict(\n",
    "        n_estimators=[80],\n",
    "        max_depth=[None],\n",
    "        max_features=['auto'],\n",
    "        min_samples_leaf=[0.00003],\n",
    "    )\n",
    "    merged_param_grid = {**default_param_grid, **param_grid}\n",
    "    pipeline_param_grid = add_key_prefix(merged_param_grid, 'regressor__')\n",
    "    \n",
    "    pipeline.set_params(regressor__n_jobs=n_jobs)\n",
    "    \n",
    "    mlflow.set_experiment(CURRENT_EXPERIMENT_NAME)\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        mlflow.log_params(merged_param_grid)\n",
    "        \n",
    "        regressor = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid=pipeline_param_grid,\n",
    "            cv=3,\n",
    "            scoring=rmse_score,\n",
    "            verbose=2,\n",
    "            refit=True,\n",
    "        )\n",
    "\n",
    "        regressor.fit(x, y)\n",
    "        \n",
    "        best_model = regressor.best_estimator_\n",
    "        best_param = add_key_prefix(regressor.best_params_)\n",
    "        best_rmse = - regressor.best_score_\n",
    "        cv_results = df_from_cv_results(regressor.cv_results_)\n",
    "\n",
    "        joblib.dump(best_model, 'out/model.sav')\n",
    "        cv_results.to_csv('out/cv_results.csv', index=False)\n",
    "        \n",
    "        mlflow.log_params(best_param)\n",
    "        mlflow.log_metrics(dict(\n",
    "            rmse=best_rmse,\n",
    "        ))\n",
    "        mlflow.log_artifact('./out/model.sav')\n",
    "        mlflow.log_artifact('./out/cv_results.csv')\n",
    "        mlflow.end_run()\n",
    "        return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(\n",
    "    pipeline,\n",
    "    x=train.drop(columns='meter_reading'),\n",
    "    y=np.log1p(train['meter_reading'].values),\n",
    "    n_jobs=-1,\n",
    "    n_estimators=[64, 80, 96],\n",
    "    max_depth=[12, 13, 14, 15],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(run_id: str = None):\n",
    "    if run_id is None:\n",
    "        model_path = 'out/model.joblib'\n",
    "    else:\n",
    "        mlflow_client = mlflow.tracking.MlflowClient()\n",
    "        model_path = mlflow_client.download_artifacts(run_id, 'model.joblib')\n",
    "\n",
    "    return joblib.load(model_path)\n",
    "\n",
    "\n",
    "def predict(df: pd.DataFrame, pipeline: Pipeline) -> pd.DataFrame:\n",
    "    x = df.iloc[:, 1:]\n",
    "    y_log1p = pipeline.predict(x)\n",
    "    y = np.expm1(y_log1p)\n",
    "    return pd.DataFrame({\n",
    "        'row_id': df.iloc[:, 0],\n",
    "        'meter_reading': y,\n",
    "    })[['row_id', 'meter_reading']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = load_model()\n",
    "predict(test, p).to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/jupyter/.kaggle/kaggle.json'\n",
      "100%|| 1.05G/1.05G [00:27<00:00, 41.0MB/s]\n",
      "Successfully submitted to ASHRAE - Great Energy Predictor III"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c ashrae-energy-prediction -f submission.csv -m \"weighted average\""
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
