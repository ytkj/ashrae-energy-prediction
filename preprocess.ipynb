{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "meters = {\n",
    "    0: 'electricity',\n",
    "    1: 'chilledwater',\n",
    "    2: 'steam',\n",
    "    3: 'hotwater',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by(df: pd.DataFrame, **kwargs) -> pd.DataFrame:\n",
    "    df_out = df\n",
    "    for key, value in kwargs.items():\n",
    "        if type(value) is list:\n",
    "            df_out = df_out[df_out[key].isin(value)]\n",
    "        else:\n",
    "            df_out = df_out[df_out[key] == value]\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_building_meta(df: pd.DataFrame, metadata: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.merge(\n",
    "        metadata,\n",
    "        on=\"building_id\",\n",
    "        how='left',\n",
    "    )\n",
    "\n",
    "\n",
    "def join_weather(df: pd.DataFrame, weather: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.merge(\n",
    "        weather,\n",
    "        on=['site_id', 'timestamp'],\n",
    "        how='left',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filler_factory(metadata: pd.DataFrame):\n",
    "    columns = ['year_built', 'floor_count']\n",
    "    df_mean_pu_si = metadata.groupby(['primary_use', 'site_id'])[columns].mean()\n",
    "    df_mean_pu = metadata.groupby('primary_use')[columns].mean()\n",
    "    df_mean_si = metadata.groupby('site_id')[columns].mean()\n",
    "    df_mean = metadata[columns].mean()\n",
    "    \n",
    "    def filler(site_id: int, primary_use: str, target: str) -> float:\n",
    "        mean_pu_si = df_mean_pu_si.loc[(primary_use, site_id), target]\n",
    "        if not np.isnan(mean_pu_si):\n",
    "            return mean_pu_si\n",
    "        mean_pu = df_mean_pu.loc[primary_use, target]\n",
    "        if not np.isnan(mean_pu):\n",
    "            return mean_pu\n",
    "        mean_si = df_mean_si.loc[site_id, target]\n",
    "        if not np.isnan(mean_si):\n",
    "            return mean_si\n",
    "        else:\n",
    "            return df_mean[target]\n",
    "    \n",
    "    return filler\n",
    "\n",
    "\n",
    "def fix_nan_building_meta(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    filler = filler_factory(df)\n",
    "    \n",
    "    def fillna(row):\n",
    "        yb = filler(row['site_id'], row['primary_use'], 'year_built')\n",
    "        fc = filler(row['site_id'], row['primary_use'], 'floor_count')\n",
    "        return pd.Series([yb, fc], index=['year_built', 'floor_count'])\n",
    "    \n",
    "    df_out = df.copy()\n",
    "    df_out.loc[:, ['year_built', 'floor_count']] = df.apply(fillna, axis=1)\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_nan_weather(w: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    # add missing datetime\n",
    "    # fill nan forward and backward for each site\n",
    "    dt_min, dt_max = w['timestamp'].min(), w['timestamp'].max()\n",
    "    empty_df = pd.DataFrame({'timestamp': pd.date_range(start=dt_min, end=dt_max, freq='H')})\n",
    "    w_tmp = pd.concat([\n",
    "        ws.merge(empty_df, on='timestamp', how='outer') \\\n",
    "            .sort_values(by='timestamp') \\\n",
    "            .fillna(method='bfill') \\\n",
    "            .fillna(method='ffill') \\\n",
    "        for site_id, ws in w.groupby('site_id')\n",
    "    ], ignore_index=True)\n",
    "    \n",
    "    # fill nan by mean over all sites\n",
    "    w_mean = w_tmp.groupby('timestamp').mean().drop(columns=['site_id']).reset_index()\n",
    "    w_mean = w_tmp.loc[:, ['site_id', 'timestamp']].merge(w_mean, on='timestamp', how='left')\n",
    "    return w_tmp.where(~w_tmp.isnull(), w_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df_in: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    df = df_in.copy()\n",
    "    \n",
    "    # timestamp\n",
    "    ts = pd.to_datetime(df['timestamp'])\n",
    "    df['week'] = ts.dt.week\n",
    "    df['weekend'] = (ts.dt.weekday >= 5).astype(int)\n",
    "    df['time_period_0-6'] = ((ts.dt.hour >= 0) & (ts.dt.hour < 6)).astype(int)\n",
    "    df['time_period_6-12'] = ((ts.dt.hour >= 6) & (ts.dt.hour < 12)).astype(int)\n",
    "    df['time_period_12-18'] = ((ts.dt.hour >= 12) & (ts.dt.hour < 18)).astype(int)\n",
    "    \n",
    "    # wind direction\n",
    "    df['wind_direction_cosine'] = np.cos(np.radians(df['wind_direction']))\n",
    "    \n",
    "    # meter\n",
    "    df['meter_category'] = df['meter'].map(meters)\n",
    "    \n",
    "    # categorycal\n",
    "    df = pd.concat([\n",
    "        df,\n",
    "        pd.get_dummies(df['primary_use'], drop_first=True),\n",
    "        pd.get_dummies(df['meter_category'], drop_first=True)\n",
    "    ], axis=1)\n",
    "    \n",
    "    # drop columns\n",
    "    df = df.drop(columns=[\n",
    "        'building_id', 'meter', 'timestamp', 'site_id', 'primary_use',\n",
    "        'meter_category', 'wind_direction'\n",
    "    ])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv', parse_dates=['timestamp'])\n",
    "building_metadata = pd.read_csv('data/building_metadata.csv')\n",
    "weather_train = pd.read_csv('data/weather_train.csv', parse_dates=['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "meter_reading                    False\n",
       "square_feet                      False\n",
       "year_built                       False\n",
       "floor_count                      False\n",
       "air_temperature                  False\n",
       "cloud_coverage                   False\n",
       "dew_temperature                  False\n",
       "precip_depth_1_hr                False\n",
       "sea_level_pressure               False\n",
       "wind_speed                       False\n",
       "week                             False\n",
       "weekend                          False\n",
       "time_period_0-6                  False\n",
       "time_period_6-12                 False\n",
       "time_period_12-18                False\n",
       "wind_direction_cosine            False\n",
       "Entertainment/public assembly    False\n",
       "Food sales and service           False\n",
       "Healthcare                       False\n",
       "Lodging/residential              False\n",
       "Manufacturing/industrial         False\n",
       "Office                           False\n",
       "Other                            False\n",
       "Parking                          False\n",
       "Public services                  False\n",
       "Religious worship                False\n",
       "Retail                           False\n",
       "Services                         False\n",
       "Technology/science               False\n",
       "Utility                          False\n",
       "Warehouse/storage                False\n",
       "electricity                      False\n",
       "hotwater                         False\n",
       "steam                            False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train = train \\\n",
    "    .pipe(join_building_meta, metadata=building_metadata.pipe(fix_nan_building_meta)) \\\n",
    "    .pipe(join_weather, weather=weather_train.pipe(fix_nan_weather)) \\\n",
    "    .pipe(add_features)\n",
    "\n",
    "dataset_train.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('dataset_train.npy', dataset_train.values, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train\n",
    "del weather_train\n",
    "del dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test.csv', parse_dates=['timestamp'])\n",
    "weather_test = pd.read_csv('data/weather_test.csv', parse_dates=['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id                           False\n",
       "square_feet                      False\n",
       "year_built                       False\n",
       "floor_count                      False\n",
       "air_temperature                  False\n",
       "cloud_coverage                   False\n",
       "dew_temperature                  False\n",
       "precip_depth_1_hr                False\n",
       "sea_level_pressure               False\n",
       "wind_speed                       False\n",
       "week                             False\n",
       "weekend                          False\n",
       "time_period_0-6                  False\n",
       "time_period_6-12                 False\n",
       "time_period_12-18                False\n",
       "wind_direction_cosine            False\n",
       "Entertainment/public assembly    False\n",
       "Food sales and service           False\n",
       "Healthcare                       False\n",
       "Lodging/residential              False\n",
       "Manufacturing/industrial         False\n",
       "Office                           False\n",
       "Other                            False\n",
       "Parking                          False\n",
       "Public services                  False\n",
       "Religious worship                False\n",
       "Retail                           False\n",
       "Services                         False\n",
       "Technology/science               False\n",
       "Utility                          False\n",
       "Warehouse/storage                False\n",
       "electricity                      False\n",
       "hotwater                         False\n",
       "steam                            False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test = test \\\n",
    "    .pipe(join_building_meta, metadata=building_metadata.pipe(fix_nan_building_meta)) \\\n",
    "    .pipe(join_weather, weather=weather_test.pipe(fix_nan_weather)) \\\n",
    "    .pipe(add_features)\n",
    "\n",
    "dataset_test.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('dataset_test.npy', dataset_test.values, allow_pickle=False)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
