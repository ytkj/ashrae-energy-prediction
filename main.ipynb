{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, Imputer, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate, KFold\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import joblib\n",
    "import mlflow\n",
    "from meteocalc import feels_like, heat_index, wind_chill, Temp\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "CURRENT_EXPERIMENT_NAME = 'catboost'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by(df: pd.DataFrame, **kwargs) -> pd.DataFrame:\n",
    "    df_out = df\n",
    "    for key, value in kwargs.items():\n",
    "        if type(value) is list:\n",
    "            df_out = df_out[df_out[key].isin(value)]\n",
    "        else:\n",
    "            df_out = df_out[df_out[key] == value]\n",
    "    return df_out\n",
    "\n",
    "\n",
    "def missing_rate(df: pd.DataFrame) -> pd.Series:\n",
    "    return df.isnull().sum() / len(df)\n",
    "\n",
    "\n",
    "def reduce_mem_usage(df: pd.DataFrame, verbose: bool = True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / (1024 ** 2)    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(\n",
    "            end_mem, 100 * (start_mem - end_mem) / start_mem)\n",
    "        )\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred) -> float:\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "rmse_score = make_scorer(rmse, greater_is_better=False)\n",
    "\n",
    "\n",
    "def add_key_prefix(d: Dict, prefix = 'best_') -> Dict:\n",
    "    return {prefix + key: value for key, value in d.items()}\n",
    "\n",
    "\n",
    "def df_from_cv_results(d: Dict):\n",
    "    df = pd.DataFrame(d)\n",
    "    score_columns = ['mean_test_score', 'mean_train_score']\n",
    "    param_columns = [c for c in df.columns if c.startswith('param_')]\n",
    "    return pd.concat([\n",
    "        -df.loc[:, score_columns],\n",
    "        df.loc[:, param_columns],\n",
    "    ], axis=1).sort_values(by='mean_test_score')\n",
    "\n",
    "\n",
    "def sample(*args, frac: float = 0.01) -> np.ndarray:\n",
    "    n_rows = args[0].shape[0]\n",
    "    random_index = np.random.choice(n_rows, int(n_rows * frac), replace=False)\n",
    "    gen = (\n",
    "        a[random_index] for a in args\n",
    "    )\n",
    "    if len(args) == 1:\n",
    "        return next(gen)\n",
    "    else:\n",
    "        return gen\n",
    "\n",
    "    \n",
    "class BaseTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, x: pd.DataFrame, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x: pd.DataFrame) -> pd.DataFrame:\n",
    "        return x\n",
    "\n",
    "\n",
    "class ColumnTransformer(BaseTransformer):\n",
    "    \n",
    "    def __init__(self, defs: Dict[str, BaseTransformer]):\n",
    "        self.defs = defs\n",
    "    \n",
    "    def fit(self, x: pd.DataFrame, y: np.ndarray = None):\n",
    "        for col, transformer in self.defs.items():\n",
    "            transformer.fit(x[col], y)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, x: pd.DataFrame) -> pd.DataFrame:\n",
    "        xp = x.copy()\n",
    "        for col, transformer in self.defs.items():\n",
    "            xp[col] = transformer.transform(x[col])\n",
    "        return xp\n",
    "    \n",
    "    def fit_transform(self, x: pd.DataFrame, y: np.ndarray = None) -> pd.DataFrame:\n",
    "        xp = x.copy()\n",
    "        for col, transformer in self.defs.items():\n",
    "            if hasattr(transformer, 'fit_transform'):\n",
    "                xp[col] = transformer.fit_transform(x[col], y)\n",
    "            else:\n",
    "                xp[col] = transformer.fit(x[col], y).transform(x[col])\n",
    "        return xp\n",
    "\n",
    "\n",
    "class WrappedLabelEncoder(BaseTransformer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.le = LabelEncoder()\n",
    "    \n",
    "    def fit(self, x, y = None):\n",
    "        self.le.fit(x)\n",
    "        return self\n",
    "\n",
    "    def transform(self, x):\n",
    "        return self.le.transform(x)\n",
    "\n",
    "\n",
    "def wind_chill_safely(t, w):\n",
    "    try:\n",
    "        return wind_chill(t, w)\n",
    "    except ValueError:\n",
    "        return Temp(10, unit='C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 289.19 Mb (53.1% reduction)\n",
      "Mem. usage decreased to 596.49 Mb (53.1% reduction)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.csv', parse_dates=['timestamp']).pipe(reduce_mem_usage)\n",
    "building_metadata = pd.read_csv('data/building_metadata.csv')\n",
    "weather_train = pd.read_csv('data/weather_train.csv', parse_dates=['timestamp'])\n",
    "\n",
    "test = pd.read_csv('data/test.csv', parse_dates=['timestamp']).pipe(reduce_mem_usage)\n",
    "weather_test = pd.read_csv('data/weather_test.csv', parse_dates=['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherImputer(BaseTransformer):\n",
    "    \n",
    "    def transform(self, w: pd.DataFrame) -> pd.DataFrame:\n",
    "        \n",
    "        # add missing datetime\n",
    "        dt_min, dt_max = w['timestamp'].min(), w['timestamp'].max()\n",
    "        empty_df = pd.DataFrame({'timestamp': pd.date_range(start=dt_min, end=dt_max, freq='H')})\n",
    "        w_out = pd.concat([\n",
    "            ws.merge(\n",
    "                empty_df, on='timestamp', how='outer'\n",
    "            ).sort_values(\n",
    "                by='timestamp'\n",
    "            ).assign(\n",
    "                site_id=site_id\n",
    "            ) for site_id, ws in w.groupby('site_id')\n",
    "        ], ignore_index=True)\n",
    "        \n",
    "        w_out['month'] = w_out['timestamp'].dt.month\n",
    "        w_out['time_period'] = pd.cut(\n",
    "            w_out['timestamp'].dt.hour,\n",
    "            bins=[0, 3, 6, 9, 12, 15, 18, 21, 25],\n",
    "            right=False, labels=False,\n",
    "        )\n",
    "        w_out = w_out.set_index(['site_id', 'month', 'time_period'])\n",
    "        w_updater = w_out.groupby(['site_id', 'month', 'time_period']).mean().fillna(method='bfill').fillna(method='ffill')\n",
    "        w_out.update(w_updater, overwrite=False)  # destroying method\n",
    "        w_out = w_out.reset_index().drop(columns=['month', 'time_period'])\n",
    "\n",
    "        # float -> uint\n",
    "        w_out['site_id'] = w_out['site_id'].astype(np.uint8)\n",
    "\n",
    "        return w_out\n",
    "\n",
    "\n",
    "class WeatherEngineerer(BaseTransformer):\n",
    "    \n",
    "    @staticmethod\n",
    "    def shift_by(wdf: pd.DataFrame, n: int) -> pd.DataFrame:\n",
    "        method = 'bfill' if n > 0 else 'ffill'\n",
    "        return pd.concat([\n",
    "            ws.iloc[:, [2, 4, 8]].shift(n).fillna(method=method) for _, ws in wdf.groupby('site_id')\n",
    "        ], axis=0)\n",
    "    \n",
    "    def weather_weighted_average(self, w: pd.DataFrame, hours: int = 5) -> pd.DataFrame:\n",
    "        ahours = abs(hours)\n",
    "        sign = int(hours / ahours)\n",
    "        w_weighted_average = sum(\n",
    "            [self.shift_by(w, (i+1)*sign) * (ahours-i) for i in range(ahours)]\n",
    "        ) / (np.arange(ahours) + 1).sum()\n",
    "\n",
    "        w_weighted_average.columns = ['{0}_wa{1}'.format(c, hours) for c in w_weighted_average.columns]\n",
    "\n",
    "        return pd.concat([w, w_weighted_average], axis=1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def dwdt(df: pd.DataFrame, base_col: str) -> pd.DataFrame:\n",
    "        df_out = df.copy()\n",
    "        df_out[base_col + '_dt_wa1'] = df[base_col] - df[base_col + '_wa1']\n",
    "        df_out[base_col + '_dt_wa-1'] = df[base_col] - df[base_col + '_wa-1']\n",
    "        df_out[base_col + '_dt_wa5'] = df[base_col] - df[base_col + '_wa5']\n",
    "        df_out[base_col + '_dt_wa-5'] = df[base_col] - df[base_col + '_wa-5']\n",
    "        return df_out\n",
    "    \n",
    "    @staticmethod\n",
    "    def wet(df: pd.DataFrame, suffix: str = '') -> pd.DataFrame:\n",
    "        df_out = df.copy()\n",
    "        df_out['wet' + suffix] = df['air_temperature' + suffix] - df['dew_temperature' + suffix]\n",
    "        return df_out\n",
    "        \n",
    "    @staticmethod\n",
    "    def meteocalc(w_in: pd.DataFrame, suffix: str = '') -> pd.DataFrame:\n",
    "\n",
    "        w = w_in.assign(**{\n",
    "            'relative_humidity' + suffix: 100 * (\n",
    "                np.exp(\n",
    "                    (17.625 * w_in['dew_temperature' + suffix]) / (243.04 + w_in['dew_temperature' + suffix])\n",
    "                ) / np.exp(\n",
    "                    (17.625 * w_in['air_temperature' + suffix]) / (243.04 + w_in['air_temperature' + suffix])\n",
    "                )\n",
    "            )\n",
    "        })\n",
    "        return w.assign(**{\n",
    "            'feels_like' + suffix: w.apply(lambda row: feels_like(\n",
    "                Temp(row['air_temperature' + suffix], unit='C'),\n",
    "                row['relative_humidity' + suffix],\n",
    "                row['wind_speed' + suffix]\n",
    "            ).c, axis=1)\n",
    "        }).assign(**{\n",
    "            'heat_index' + suffix: w.apply(lambda row: heat_index(\n",
    "                Temp(row['air_temperature' + suffix], unit='C'),\n",
    "                row['relative_humidity' + suffix]\n",
    "            ).c, axis=1)\n",
    "        }).assign(**{\n",
    "            'wind_chill' + suffix: w.apply(lambda row: wind_chill_safely(\n",
    "                Temp(row['air_temperature' + suffix], unit='C'),\n",
    "                row['wind_speed' + suffix]\n",
    "            ).c, axis=1)\n",
    "        })\n",
    "    \n",
    "    def transform(self, w_in: pd.DataFrame) -> pd.DataFrame:\n",
    "        w = w_in.pipe(\n",
    "            self.weather_weighted_average, hours=1\n",
    "        ).pipe(\n",
    "            self.weather_weighted_average, hours=-1\n",
    "        ).pipe(\n",
    "            self.weather_weighted_average\n",
    "        ).pipe(\n",
    "            self.weather_weighted_average, hours=-5\n",
    "        )\n",
    "\n",
    "        w = w.pipe(\n",
    "            self.dwdt, base_col='air_temperature'\n",
    "        ).pipe(\n",
    "            self.dwdt, base_col='dew_temperature'\n",
    "        ).pipe(\n",
    "            self.dwdt, base_col='wind_speed'\n",
    "        ).pipe(\n",
    "            self.wet\n",
    "        ).pipe(\n",
    "            self.wet, suffix='_wa1'\n",
    "        ).pipe(\n",
    "            self.wet, suffix='_wa-1'\n",
    "        ).pipe(\n",
    "            self.wet, suffix='_wa5'\n",
    "        ).pipe(\n",
    "            self.wet, suffix='_wa-5'\n",
    "        ).pipe(\n",
    "            self.meteocalc\n",
    "        ).pipe(\n",
    "            self.meteocalc, suffix='_wa1'\n",
    "        ).pipe(\n",
    "            self.meteocalc, suffix='_wa-1'\n",
    "        ).pipe(\n",
    "            self.meteocalc, suffix='_wa5'\n",
    "        ).pipe(\n",
    "            self.meteocalc, suffix='_wa-5'\n",
    "        )\n",
    "\n",
    "        return w\n",
    "\n",
    "\n",
    "\n",
    "class WindDirectionEncoder(BaseTransformer):\n",
    "    \n",
    "    @staticmethod\n",
    "    def _from_degree(degree: int) -> int:\n",
    "        val = int((degree / 22.5) + 0.5)\n",
    "        arr = [i for i in range(0,16)]\n",
    "        return arr[(val % 16)]\n",
    "    \n",
    "    def transform(self, x: pd.Series) -> pd.Series:\n",
    "        return x.apply(self._from_degree)\n",
    "\n",
    "\n",
    "class WindSpeedEncoder(BaseTransformer):\n",
    "    \n",
    "    def transform(self, x: pd.Series) -> pd.Series:\n",
    "        return pd.cut(\n",
    "            x,\n",
    "            bins=[0, 0.3, 1.6, 3.4, 5.5, 8, 10.8, 13.9, 17.2, 20.8, 24.5, 28.5, 33, 1000],\n",
    "            right=False, labels=False,\n",
    "        )\n",
    "\n",
    "    \n",
    "weather_pipeline = Pipeline(steps=[\n",
    "    ('impute_missing_value', WeatherImputer()),\n",
    "    ('feature_engineering', WeatherEngineerer()),\n",
    "    ('label_encode', ColumnTransformer({\n",
    "        'wind_direction': WindDirectionEncoder(),\n",
    "        'wind_speed': WindSpeedEncoder(),\n",
    "        'wind_speed_wa1': WindSpeedEncoder(),\n",
    "        'wind_speed_wa-1': WindSpeedEncoder(),    \n",
    "        'wind_speed_wa5': WindSpeedEncoder(),\n",
    "        'wind_speed_wa-5': WindSpeedEncoder(),    \n",
    "    }))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Metadata Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildingMetadataEngineerer(BaseTransformer):\n",
    "    \n",
    "    def transform(self, bm_in: pd.DataFrame) -> pd.DataFrame:\n",
    "        bm = bm_in.copy()\n",
    "        bm['log_square_feet'] = np.log1p(bm['square_feet'])\n",
    "        bm['square_feet_per_floor'] = bm['square_feet'] / bm['floor_count']\n",
    "        bm['log_square_feet_per_floor'] = bm['log_square_feet'] / bm['floor_count']\n",
    "        bm['building_age'] = 2019 - bm['year_built']\n",
    "        bm['square_feet_per_age'] = bm['square_feet'] / bm['building_age']\n",
    "        bm['log_square_feet_per_age'] = bm['log_square_feet'] / bm['building_age']\n",
    "        return bm\n",
    "\n",
    "\n",
    "class BuildingMetadataImputer(BaseTransformer):\n",
    "    \n",
    "    def transform(self, bm: pd.DataFrame) -> pd.DataFrame:\n",
    "        return bm.fillna(-999)\n",
    "\n",
    "\n",
    "building_metadata_pipeline = Pipeline(steps=[\n",
    "    ('feature_engineering', BuildingMetadataEngineerer()),\n",
    "    ('impute_missing_value', BuildingMetadataImputer()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildingMetaJoiner(BaseTransformer):\n",
    "    \n",
    "    def __init__(self, bm: pd.DataFrame = None):\n",
    "        self.bm = bm\n",
    "    \n",
    "    def transform(self, x: pd.DataFrame) -> pd.DataFrame:\n",
    "        if self.bm is None:\n",
    "            return x\n",
    "        else:\n",
    "            return x.merge(\n",
    "                self.bm,\n",
    "                on='building_id',\n",
    "                how='left',\n",
    "            )\n",
    "\n",
    "    \n",
    "class WeatherJoiner(BaseTransformer):\n",
    "    \n",
    "    def __init__(self, w: pd.DataFrame = None):\n",
    "        self.w = w\n",
    "    \n",
    "    def transform(self, x: pd.DataFrame) -> pd.DataFrame:\n",
    "        if self.w is None:\n",
    "            return x\n",
    "        else:\n",
    "            return x.merge(\n",
    "                self.w,\n",
    "                on=['site_id', 'timestamp'],\n",
    "                how='left',\n",
    "            )\n",
    "\n",
    "\n",
    "class DatetimeFeatureEngineerer(BaseTransformer):\n",
    "    \n",
    "    def __init__(self, col: str = 'timestamp'):\n",
    "        self.col = col\n",
    "    \n",
    "    def transform(self, x: pd.DataFrame) -> pd.DataFrame:\n",
    "        xp = x.copy()\n",
    "        ts = x[self.col]\n",
    "        xp['month'] = ts.dt.month.astype(np.int8)\n",
    "        xp['week'] = ts.dt.week.astype(np.int8)\n",
    "        xp['day_of_week'] = ts.dt.weekday.astype(np.int8)\n",
    "        xp['time_period'] = pd.cut(\n",
    "            ts.dt.hour,\n",
    "            bins=[0, 3, 6, 9, 12, 15, 18, 21, 25],\n",
    "            right=False, labels=False,\n",
    "        )\n",
    "        \n",
    "        holidays = [\n",
    "            '2016-01-01', '2016-01-18', '2016-02-15', '2016-05-30', '2016-07-04',\n",
    "            '2016-09-05', '2016-10-10', '2016-11-11', '2016-11-24', '2016-12-26',\n",
    "            '2017-01-01', '2017-01-16', '2017-02-20', '2017-05-29', '2017-07-04',\n",
    "            '2017-09-04', '2017-10-09', '2017-11-10', '2017-11-23', '2017-12-25',\n",
    "            '2018-01-01', '2018-01-15', '2018-02-19', '2018-05-28', '2018-07-04',\n",
    "            '2018-09-03', '2018-10-08', '2018-11-12', '2018-11-22', '2018-12-25',\n",
    "            '2019-01-01'\n",
    "        ]\n",
    "        xp['is_holiday'] = (ts.dt.date.astype('str').isin(holidays)).astype(np.int8)\n",
    "        return xp\n",
    "\n",
    "\n",
    "class TargetEncoder(BaseTransformer):\n",
    "    \n",
    "    def __init__(self, cv: int = 5, smoothing: int = 1):\n",
    "        self.agg = None\n",
    "        self.cv = cv\n",
    "        self.smoothing = 1\n",
    "    \n",
    "    def transform(self, x: pd.Series):        \n",
    "        if self.agg is None:\n",
    "            raise ValueError('you shold fit() before predict()')\n",
    "        encoded = pd.merge(x, self.agg, left_on=x.name, right_index=True, how='left')\n",
    "        encoded = encoded.fillna(encoded.mean())\n",
    "        xp = encoded['y']\n",
    "        xp.name = x.name\n",
    "        return xp\n",
    "    \n",
    "    def fit_transform(self, x: pd.Series, y: np.ndarray = None) -> pd.Series:\n",
    "        df = pd.DataFrame({'x': x, 'y': y})\n",
    "        self.agg = df.groupby('x').mean()\n",
    "        fold = KFold(n_splits=self.cv, shuffle=True)\n",
    "        xp = x.copy()\n",
    "        for idx_train, idx_test in fold.split(x):\n",
    "            df_train = df.loc[idx_train, :]\n",
    "            df_test = df.loc[idx_test, :]\n",
    "            agg_train = df_train.groupby('x').mean()\n",
    "            encoded = pd.merge(df_test, agg_train, left_on='x', right_index=True, how='left', suffixes=('', '_mean'))['y_mean']\n",
    "            encoded = encoded.fillna(encoded.mean())\n",
    "            xp[encoded.index] = encoded\n",
    "        return xp\n",
    "\n",
    "\n",
    "class ColumnDropper(BaseTransformer):\n",
    "    \n",
    "    def __init__(self, cols: List[str]):\n",
    "        self.cols = cols\n",
    "    \n",
    "    def transform(self, x: pd.DataFrame, y = None) -> pd.DataFrame:\n",
    "        return x.drop(columns=self.cols)\n",
    "\n",
    "\n",
    "class ArrayTransformer(BaseTransformer):\n",
    "    \n",
    "    def transform(self, x: pd.DataFrame, y = None) -> np.ndarray:\n",
    "        return x.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_metadata_pipeline_out = building_metadata_pipeline.fit_transform(\n",
    "    building_metadata\n",
    ")\n",
    "weather_pipeline_out = weather_pipeline.fit_transform(\n",
    "    pd.concat([weather_train, weather_test], axis=0, ignore_index=True)\n",
    ")\n",
    "\n",
    "\n",
    "def pipeline_factory() -> Pipeline:\n",
    "    return Pipeline(steps=[\n",
    "\n",
    "        # join\n",
    "        ('join_building_meta', BuildingMetaJoiner(\n",
    "            building_metadata_pipeline_out\n",
    "        )),\n",
    "        ('join_weather', WeatherJoiner(\n",
    "            weather_pipeline_out\n",
    "        )),\n",
    "\n",
    "        # feature engineering\n",
    "        ('feature_engineering_from_datetime', DatetimeFeatureEngineerer()),\n",
    "#         ('target_encode', ColumnTransformer({\n",
    "#             'primary_use': TargetEncoder(),\n",
    "#             'meter': TargetEncoder(),\n",
    "#             'cloud_coverage': TargetEncoder(),\n",
    "#             'time_period': TargetEncoder(),\n",
    "#             'wind_direction': TargetEncoder(),\n",
    "#             'wind_speed': TargetEncoder(),\n",
    "#             'wind_speed_wa1': TargetEncoder(),\n",
    "#             'wind_speed_wa-1': TargetEncoder(),\n",
    "#             'wind_speed_wa5': TargetEncoder(),\n",
    "#             'wind_speed_wa-5': TargetEncoder(),\n",
    "#         })),\n",
    "\n",
    "        # drop columns\n",
    "        ('drop_columns', ColumnDropper([\n",
    "            'building_id', 'timestamp', 'site_id', 'precip_depth_1_hr',\n",
    "        ])),\n",
    "\n",
    "        # pd.DataFrame -> np.ndarray\n",
    "#         ('df_to_array', ArrayTransformer()),\n",
    "\n",
    "        # regressor\n",
    "#         ('regressor', RandomForestRegressor()),\n",
    "#         ('regressor', CatBoostRegressor()),\n",
    "\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>floor_count</th>\n",
       "      <th>log_square_feet</th>\n",
       "      <th>square_feet_per_floor</th>\n",
       "      <th>log_square_feet_per_floor</th>\n",
       "      <th>building_age</th>\n",
       "      <th>square_feet_per_age</th>\n",
       "      <th>log_square_feet_per_age</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>cloud_coverage</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>air_temperature_wa1</th>\n",
       "      <th>dew_temperature_wa1</th>\n",
       "      <th>wind_speed_wa1</th>\n",
       "      <th>air_temperature_wa-1</th>\n",
       "      <th>dew_temperature_wa-1</th>\n",
       "      <th>wind_speed_wa-1</th>\n",
       "      <th>air_temperature_wa5</th>\n",
       "      <th>dew_temperature_wa5</th>\n",
       "      <th>wind_speed_wa5</th>\n",
       "      <th>air_temperature_wa-5</th>\n",
       "      <th>dew_temperature_wa-5</th>\n",
       "      <th>wind_speed_wa-5</th>\n",
       "      <th>air_temperature_dt_wa1</th>\n",
       "      <th>air_temperature_dt_wa-1</th>\n",
       "      <th>air_temperature_dt_wa5</th>\n",
       "      <th>air_temperature_dt_wa-5</th>\n",
       "      <th>dew_temperature_dt_wa1</th>\n",
       "      <th>dew_temperature_dt_wa-1</th>\n",
       "      <th>dew_temperature_dt_wa5</th>\n",
       "      <th>dew_temperature_dt_wa-5</th>\n",
       "      <th>wind_speed_dt_wa1</th>\n",
       "      <th>wind_speed_dt_wa-1</th>\n",
       "      <th>wind_speed_dt_wa5</th>\n",
       "      <th>wind_speed_dt_wa-5</th>\n",
       "      <th>wet</th>\n",
       "      <th>wet_wa1</th>\n",
       "      <th>wet_wa-1</th>\n",
       "      <th>wet_wa5</th>\n",
       "      <th>wet_wa-5</th>\n",
       "      <th>relative_humidity</th>\n",
       "      <th>feels_like</th>\n",
       "      <th>heat_index</th>\n",
       "      <th>wind_chill</th>\n",
       "      <th>relative_humidity_wa1</th>\n",
       "      <th>feels_like_wa1</th>\n",
       "      <th>heat_index_wa1</th>\n",
       "      <th>wind_chill_wa1</th>\n",
       "      <th>relative_humidity_wa-1</th>\n",
       "      <th>feels_like_wa-1</th>\n",
       "      <th>heat_index_wa-1</th>\n",
       "      <th>wind_chill_wa-1</th>\n",
       "      <th>relative_humidity_wa5</th>\n",
       "      <th>feels_like_wa5</th>\n",
       "      <th>heat_index_wa5</th>\n",
       "      <th>wind_chill_wa5</th>\n",
       "      <th>relative_humidity_wa-5</th>\n",
       "      <th>feels_like_wa-5</th>\n",
       "      <th>heat_index_wa-5</th>\n",
       "      <th>wind_chill_wa-5</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>time_period</th>\n",
       "      <th>is_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Education</td>\n",
       "      <td>198488</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>12.198489</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.8</td>\n",
       "      <td>1016.1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>21.1</td>\n",
       "      <td>12.2</td>\n",
       "      <td>3</td>\n",
       "      <td>18.3</td>\n",
       "      <td>12.8</td>\n",
       "      <td>2</td>\n",
       "      <td>22.300000</td>\n",
       "      <td>11.586667</td>\n",
       "      <td>2</td>\n",
       "      <td>17.626667</td>\n",
       "      <td>13.373333</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-2.300000</td>\n",
       "      <td>2.373333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.213333</td>\n",
       "      <td>-0.573333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>7.2</td>\n",
       "      <td>8.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>10.713333</td>\n",
       "      <td>4.253333</td>\n",
       "      <td>63.235822</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>19.706713</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>56.808982</td>\n",
       "      <td>21.100000</td>\n",
       "      <td>20.748901</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>70.302206</td>\n",
       "      <td>18.3</td>\n",
       "      <td>18.021224</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50.700087</td>\n",
       "      <td>22.300000</td>\n",
       "      <td>21.909391</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>76.140477</td>\n",
       "      <td>17.626667</td>\n",
       "      <td>17.433001</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>214505</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>12.276093</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7396.724138</td>\n",
       "      <td>0.423314</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.3</td>\n",
       "      <td>1025.8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>13.3</td>\n",
       "      <td>12.2</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2</td>\n",
       "      <td>13.420000</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>2</td>\n",
       "      <td>23.040000</td>\n",
       "      <td>16.006667</td>\n",
       "      <td>2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>2.180000</td>\n",
       "      <td>-7.440000</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>-2.706667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.433333</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.220000</td>\n",
       "      <td>7.033333</td>\n",
       "      <td>86.191268</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>15.466105</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>93.051517</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>13.115234</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>72.938767</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.960068</td>\n",
       "      <td>10.0</td>\n",
       "      <td>92.326782</td>\n",
       "      <td>13.420000</td>\n",
       "      <td>13.228310</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>64.590876</td>\n",
       "      <td>23.040000</td>\n",
       "      <td>23.086095</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>47200</td>\n",
       "      <td>1935.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>10.762170</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>84.0</td>\n",
       "      <td>561.904762</td>\n",
       "      <td>0.128121</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>1015.2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>2</td>\n",
       "      <td>4.646667</td>\n",
       "      <td>-4.213333</td>\n",
       "      <td>3</td>\n",
       "      <td>3.720000</td>\n",
       "      <td>-3.486667</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>-0.746667</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.313333</td>\n",
       "      <td>-0.413333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-0.900000</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>7.8</td>\n",
       "      <td>9.4</td>\n",
       "      <td>9.4</td>\n",
       "      <td>8.860000</td>\n",
       "      <td>7.206667</td>\n",
       "      <td>56.790943</td>\n",
       "      <td>2.273525</td>\n",
       "      <td>1.828430</td>\n",
       "      <td>2.273525</td>\n",
       "      <td>50.648938</td>\n",
       "      <td>3.807809</td>\n",
       "      <td>2.878056</td>\n",
       "      <td>3.807809</td>\n",
       "      <td>50.648938</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.878056</td>\n",
       "      <td>10.0</td>\n",
       "      <td>52.645658</td>\n",
       "      <td>2.722191</td>\n",
       "      <td>2.541526</td>\n",
       "      <td>2.722191</td>\n",
       "      <td>59.319445</td>\n",
       "      <td>3.720000</td>\n",
       "      <td>1.696452</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Education</td>\n",
       "      <td>258491</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>12.462620</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.522388</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1017.8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1</td>\n",
       "      <td>9.4</td>\n",
       "      <td>2</td>\n",
       "      <td>13.146667</td>\n",
       "      <td>10.513333</td>\n",
       "      <td>2</td>\n",
       "      <td>10.766667</td>\n",
       "      <td>9.306667</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.046667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-1.613333</td>\n",
       "      <td>-0.406667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.436039</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.633333</td>\n",
       "      <td>1.460000</td>\n",
       "      <td>86.313549</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>10.519298</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>82.880385</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>10.429655</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>89.269749</td>\n",
       "      <td>11.1</td>\n",
       "      <td>10.596488</td>\n",
       "      <td>10.0</td>\n",
       "      <td>84.058699</td>\n",
       "      <td>13.146667</td>\n",
       "      <td>12.711755</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>90.696896</td>\n",
       "      <td>10.766667</td>\n",
       "      <td>10.267086</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>51020</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.839993</td>\n",
       "      <td>10204.0</td>\n",
       "      <td>2.167999</td>\n",
       "      <td>95.0</td>\n",
       "      <td>537.052632</td>\n",
       "      <td>0.114105</td>\n",
       "      <td>13.3</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1015.8</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>13.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>15.013333</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>9.960000</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.713333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.506667</td>\n",
       "      <td>1.126667</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.513333</td>\n",
       "      <td>3.140000</td>\n",
       "      <td>80.418244</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>12.785365</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>77.340598</td>\n",
       "      <td>13.900000</td>\n",
       "      <td>13.365005</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>80.418244</td>\n",
       "      <td>13.3</td>\n",
       "      <td>12.785365</td>\n",
       "      <td>10.0</td>\n",
       "      <td>74.416405</td>\n",
       "      <td>15.013333</td>\n",
       "      <td>14.513317</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>81.256645</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>12.587257</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   meter primary_use  square_feet  year_built  floor_count  log_square_feet  \\\n",
       "0      1   Education       198488      -999.0       -999.0        12.198489   \n",
       "1      0   Education       214505      1990.0       -999.0        12.276093   \n",
       "2      0   Education        47200      1935.0       -999.0        10.762170   \n",
       "3      2   Education       258491      -999.0       -999.0        12.462620   \n",
       "4      0   Education        51020      1924.0          5.0        10.839993   \n",
       "\n",
       "   square_feet_per_floor  log_square_feet_per_floor  building_age  \\\n",
       "0                 -999.0                -999.000000        -999.0   \n",
       "1                 -999.0                -999.000000          29.0   \n",
       "2                 -999.0                -999.000000          84.0   \n",
       "3                 -999.0                -999.000000        -999.0   \n",
       "4                10204.0                   2.167999          95.0   \n",
       "\n",
       "   square_feet_per_age  log_square_feet_per_age  air_temperature  \\\n",
       "0          -999.000000              -999.000000             20.0   \n",
       "1          7396.724138                 0.423314             15.6   \n",
       "2           561.904762                 0.128121              3.9   \n",
       "3          -999.000000              -999.000000             11.1   \n",
       "4           537.052632                 0.114105             13.3   \n",
       "\n",
       "   cloud_coverage  dew_temperature  sea_level_pressure  wind_direction  \\\n",
       "0        0.000000             12.8              1016.1               7   \n",
       "1        0.000000             13.3              1025.8               4   \n",
       "2        4.000000             -3.9              1015.2               9   \n",
       "3        0.522388              8.9              1017.8               5   \n",
       "4        2.000000             10.0              1015.8              13   \n",
       "\n",
       "   wind_speed  air_temperature_wa1  dew_temperature_wa1  wind_speed_wa1  \\\n",
       "0           3                 21.1                 12.2               3   \n",
       "1           2                 13.3                 12.2               2   \n",
       "2           3                  5.0                 -4.4               3   \n",
       "3           2                 11.1                  8.3               2   \n",
       "4           3                 13.9                 10.0               3   \n",
       "\n",
       "   air_temperature_wa-1  dew_temperature_wa-1  wind_speed_wa-1  \\\n",
       "0                  18.3                  12.8                2   \n",
       "1                  20.0                  15.0                2   \n",
       "2                   5.0                  -4.4                2   \n",
       "3                  11.1                   9.4                2   \n",
       "4                  13.3                  10.0                2   \n",
       "\n",
       "   air_temperature_wa5  dew_temperature_wa5  wind_speed_wa5  \\\n",
       "0            22.300000            11.586667               2   \n",
       "1            13.420000            12.200000               2   \n",
       "2             4.646667            -4.213333               3   \n",
       "3            13.146667            10.513333               2   \n",
       "4            15.013333            10.500000               3   \n",
       "\n",
       "   air_temperature_wa-5  dew_temperature_wa-5  wind_speed_wa-5  \\\n",
       "0             17.626667             13.373333                2   \n",
       "1             23.040000             16.006667                2   \n",
       "2              3.720000             -3.486667                2   \n",
       "3             10.766667              9.306667                2   \n",
       "4             13.100000              9.960000                2   \n",
       "\n",
       "   air_temperature_dt_wa1  air_temperature_dt_wa-1  air_temperature_dt_wa5  \\\n",
       "0                    -1.1                      1.7               -2.300000   \n",
       "1                     2.3                     -4.4                2.180000   \n",
       "2                    -1.1                     -1.1               -0.746667   \n",
       "3                     0.0                      0.0               -2.046667   \n",
       "4                    -0.6                      0.0               -1.713333   \n",
       "\n",
       "   air_temperature_dt_wa-5  dew_temperature_dt_wa1  dew_temperature_dt_wa-1  \\\n",
       "0                 2.373333                     0.6                      0.0   \n",
       "1                -7.440000                     1.1                     -1.7   \n",
       "2                 0.180000                     0.5                      0.5   \n",
       "3                 0.333333                     0.6                     -0.5   \n",
       "4                 0.200000                     0.0                      0.0   \n",
       "\n",
       "   dew_temperature_dt_wa5  dew_temperature_dt_wa-5  wind_speed_dt_wa1  \\\n",
       "0                1.213333                -0.573333                0.5   \n",
       "1                1.100000                -2.706667                0.0   \n",
       "2                0.313333                -0.413333                0.5   \n",
       "3               -1.613333                -0.406667                0.5   \n",
       "4               -0.500000                 0.040000                0.0   \n",
       "\n",
       "   wind_speed_dt_wa-1  wind_speed_dt_wa5  wind_speed_dt_wa-5  wet  wet_wa1  \\\n",
       "0                 1.5           1.600000            2.166667  7.2      8.9   \n",
       "1                 0.0          -0.166667           -0.433333  2.3      1.1   \n",
       "2                 1.5          -0.900000            1.266667  7.8      9.4   \n",
       "3                 0.5           0.436039            0.433333  2.2      2.8   \n",
       "4                 0.5          -0.506667            1.126667  3.3      3.9   \n",
       "\n",
       "   wet_wa-1    wet_wa5  wet_wa-5  relative_humidity  feels_like  heat_index  \\\n",
       "0       5.5  10.713333  4.253333          63.235822   20.000000   19.706713   \n",
       "1       5.0   1.220000  7.033333          86.191268   15.600000   15.466105   \n",
       "2       9.4   8.860000  7.206667          56.790943    2.273525    1.828430   \n",
       "3       1.7   2.633333  1.460000          86.313549   11.100000   10.519298   \n",
       "4       3.3   4.513333  3.140000          80.418244   13.300000   12.785365   \n",
       "\n",
       "   wind_chill  relative_humidity_wa1  feels_like_wa1  heat_index_wa1  \\\n",
       "0   10.000000              56.808982       21.100000       20.748901   \n",
       "1   10.000000              93.051517       13.300000       13.115234   \n",
       "2    2.273525              50.648938        3.807809        2.878056   \n",
       "3   10.000000              82.880385       11.100000       10.429655   \n",
       "4   10.000000              77.340598       13.900000       13.365005   \n",
       "\n",
       "   wind_chill_wa1  relative_humidity_wa-1  feels_like_wa-1  heat_index_wa-1  \\\n",
       "0       10.000000               70.302206             18.3        18.021224   \n",
       "1       10.000000               72.938767             20.0        19.960068   \n",
       "2        3.807809               50.648938              5.0         2.878056   \n",
       "3       10.000000               89.269749             11.1        10.596488   \n",
       "4       10.000000               80.418244             13.3        12.785365   \n",
       "\n",
       "   wind_chill_wa-1  relative_humidity_wa5  feels_like_wa5  heat_index_wa5  \\\n",
       "0             10.0              50.700087       22.300000       21.909391   \n",
       "1             10.0              92.326782       13.420000       13.228310   \n",
       "2             10.0              52.645658        2.722191        2.541526   \n",
       "3             10.0              84.058699       13.146667       12.711755   \n",
       "4             10.0              74.416405       15.013333       14.513317   \n",
       "\n",
       "   wind_chill_wa5  relative_humidity_wa-5  feels_like_wa-5  heat_index_wa-5  \\\n",
       "0       10.000000               76.140477        17.626667        17.433001   \n",
       "1       10.000000               64.590876        23.040000        23.086095   \n",
       "2        2.722191               59.319445         3.720000         1.696452   \n",
       "3       10.000000               90.696896        10.766667        10.267086   \n",
       "4       10.000000               81.256645        13.100000        12.587257   \n",
       "\n",
       "   wind_chill_wa-5  month  week  day_of_week  time_period  is_holiday  \n",
       "0             10.0     11    47            1            0           0  \n",
       "1             10.0      8    34            2            4           0  \n",
       "2             10.0      1     4            6            2           0  \n",
       "3             10.0     12    48            5            1           0  \n",
       "4             10.0      6    26            0            3           0  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pipeline_factory().fit_transform(\n",
    "    train.sample(frac=0.001).drop(columns='meter_reading')\n",
    ")\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\n",
    "    'meter', 'primary_use', 'wind_direction', 'wind_speed',\n",
    "    'wind_speed_wa1', 'wind_speed_wa-1', 'wind_speed_wa5', 'wind_speed_wa-5',\n",
    "    'day_of_week', 'time_period', 'is_holiday',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_catboost(p: Pipeline, df: pd.DataFrame, **params):\n",
    "    \n",
    "    x = p.fit_transform(df.drop(columns='meter_reading'))\n",
    "    y = np.log1p(df['meter_reading'].values)\n",
    "    \n",
    "    models = []\n",
    "\n",
    "    mlflow.set_experiment(CURRENT_EXPERIMENT_NAME)\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        for i_train, i_val in KFold(n_splits=3, shuffle=True).split(x):\n",
    "            \n",
    "            x_train, x_val = x.loc[i_train, :], x.loc[i_val, :]\n",
    "            y_train, y_val = y[i_train], y[i_val]\n",
    "            \n",
    "            model = CatBoostRegressor(**params)\n",
    "        \n",
    "            model.fit(\n",
    "                x_train, y_train,\n",
    "                cat_features=cat_features,\n",
    "                eval_set=(x_val, y_val),\n",
    "                logging_level='Verbose',\n",
    "            )\n",
    "            \n",
    "            models.append(model)\n",
    "        \n",
    "        mlflow.log_metrics(dict(\n",
    "            rmse_train=np.mean([m.best_score_['learn']['RMSE'] for m in models]),\n",
    "            rmse_val=np.mean([m.best_score_['validation']['RMSE'] for m in models]),\n",
    "        ))\n",
    "        eval_result = pd.DataFrame({\n",
    "            'RMSE_train': models[0].evals_result_['learn']['RMSE'],\n",
    "            'RMSE_eval': models[0].evals_result_['validation']['RMSE']\n",
    "        })\n",
    "        eval_result.to_csv('out/eval_result.csv', index=False)\n",
    "        mlflow.log_artifact('out/eval_result.csv')\n",
    "        for i, m in enumerate(models):            \n",
    "            joblib.dump(m, 'out/model{0}.joblib'.format(i))\n",
    "            mlflow.log_artifact('out/model{0}.joblib'.format(i))\n",
    "        return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_catboost(\n",
    "    pipeline_factory(),\n",
    "    train.sample(frac=0.001),\n",
    "    n_estimators=10,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.1,\n",
    "    early_stopping_rounds=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_catboost(run_id: str = None):\n",
    "    if run_id is None:\n",
    "        model_paths = ['out/model{0}.joblib'.format(i) for i in range(3)]\n",
    "    else:\n",
    "        c = mlflow.tracking.MlflowClient()\n",
    "        model_paths = [c.download_artifacts(run_id, 'model{0}.joblib'.format(i)) for i in range(3)]\n",
    "\n",
    "    return [joblib.load(p) for p in model_paths]\n",
    "\n",
    "\n",
    "def predict_catboost(df: pd.DataFrame, p: Pipeline, models) -> pd.DataFrame:\n",
    "    x = df.iloc[:, 1:]\n",
    "    y = np.mean([\n",
    "        np.expm1(\n",
    "            m.predict(p.transform(x))\n",
    "        ) for m in models\n",
    "    ], axis=0)\n",
    "    y = np.clip(y, a_min=0, a_max=None)\n",
    "    return pd.DataFrame({\n",
    "        'row_id': df.iloc[:, 0],\n",
    "        'meter_reading': y,\n",
    "    })[['row_id', 'meter_reading']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = load_model_catboost()\n",
    "predict_catboost(test, pipeline_factory(), ms).to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(pipeline: Pipeline, df: pd.DataFrame, n_jobs: int = -1, **params) -> Tuple[float, float]:\n",
    "    \n",
    "    x = df.drop(columns='meter_reading')\n",
    "    y = np.log1p(df['meter_reading'].values)\n",
    "\n",
    "    default_params = dict(\n",
    "        n_estimators=10,\n",
    "        max_depth=None,\n",
    "        max_features='auto',\n",
    "        min_samples_leaf=1,\n",
    "    )\n",
    "    merged_params = {**default_params, **params}\n",
    "\n",
    "    pipeline_params = {**merged_params, 'n_jobs': n_jobs}\n",
    "    pipeline_params = add_key_prefix(pipeline_params, 'regressor__')\n",
    "    pipeline.set_params(**pipeline_params)\n",
    "    \n",
    "    mlflow.set_experiment(CURRENT_EXPERIMENT_NAME)\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        mlflow.log_params(merged_params)\n",
    "        scores = cross_validate(\n",
    "            pipeline, x, y,\n",
    "            cv=3,\n",
    "            scoring=rmse_score,\n",
    "            return_train_score=True,\n",
    "            verbose=2,\n",
    "        )\n",
    "        \n",
    "        rmse_val = - np.mean(scores['test_score'])\n",
    "        rmse_train = - np.mean(scores['train_score'])\n",
    "        mlflow.log_metrics(dict(\n",
    "            rmse_val=rmse_val,\n",
    "            rmse_train=rmse_train,\n",
    "        ))\n",
    "        return rmse_val, rmse_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv(\n",
    "    pipeline_factory(),\n",
    "    train,\n",
    "    n_jobs=-1,\n",
    "    n_estimators=64,\n",
    "    min_samples_leaf=0.00001,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest One shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneshot(pipeline: Pipeline, df: pd.DataFrame, **params):\n",
    "    \n",
    "    x = df.drop(columns='meter_reading')\n",
    "    y = np.log1p(df['meter_reading'].values)\n",
    "\n",
    "    default_params = dict(\n",
    "        n_estimators=10,\n",
    "        max_depth=None,\n",
    "        max_features='auto',\n",
    "        min_samples_leaf=1,\n",
    "    )\n",
    "    merged_params = {**default_params, **params}\n",
    "\n",
    "    pipeline_params = {**merged_params, 'n_jobs': -1, 'verbose': 2}\n",
    "    pipeline_params = add_key_prefix(pipeline_params, 'regressor__')\n",
    "    pipeline.set_params(**pipeline_params)\n",
    "\n",
    "    mlflow.set_experiment(CURRENT_EXPERIMENT_NAME)\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        mlflow.log_params(merged_params)\n",
    "\n",
    "        pipeline.fit(x, y)\n",
    "        joblib.dump(pipeline, 'out/pipeline.joblib', compress=1)\n",
    "        \n",
    "        score = rmse(y, pipeline.predict(x))\n",
    "        \n",
    "        mlflow.log_metrics(dict(rmse_train=score))\n",
    "        mlflow.log_artifact('out/pipeline.joblib')\n",
    "        \n",
    "        return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = oneshot(pipeline_factory(), train, n_estimators=64, min_samples_leaf=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(pipeline: Pipeline, df: pd.DataFrame, n_jobs: int = -1, **param_grid):\n",
    "            \n",
    "    x = df.drop(columns='meter_reading')\n",
    "    y = np.log1p(df['meter_reading'].values)\n",
    "\n",
    "    default_param_grid = dict(\n",
    "        n_estimators=[80],\n",
    "        max_depth=[None],\n",
    "        max_features=['auto'],\n",
    "        min_samples_leaf=[0.00001],\n",
    "    )\n",
    "    merged_param_grid = {**default_param_grid, **param_grid}\n",
    "    pipeline_param_grid = add_key_prefix(merged_param_grid, 'regressor__')\n",
    "    \n",
    "    pipeline.set_params(regressor__n_jobs=n_jobs)\n",
    "    \n",
    "    mlflow.set_experiment(CURRENT_EXPERIMENT_NAME)\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        mlflow.log_params(merged_param_grid)\n",
    "        \n",
    "        regressor = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid=pipeline_param_grid,\n",
    "            cv=3,\n",
    "            scoring=rmse_score,\n",
    "            verbose=2,\n",
    "            refit=True,\n",
    "        )\n",
    "\n",
    "        regressor.fit(x, y)\n",
    "        \n",
    "        best_model = regressor.best_estimator_\n",
    "        best_param = add_key_prefix(regressor.best_params_)\n",
    "        best_rmse = - regressor.best_score_\n",
    "        cv_results = df_from_cv_results(regressor.cv_results_)\n",
    "\n",
    "        joblib.dump(best_model, 'out/pipeline.joblib')\n",
    "        cv_results.to_csv('out/cv_results.csv', index=False)\n",
    "        \n",
    "        mlflow.log_params(best_param)\n",
    "        mlflow.log_metrics(dict(\n",
    "            rmse=best_rmse,\n",
    "        ))\n",
    "        mlflow.log_artifact('./out/pipeline.joblib')\n",
    "        mlflow.log_artifact('./out/cv_results.csv')\n",
    "        mlflow.end_run()\n",
    "        return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(\n",
    "    pipeline_factory(),\n",
    "    train,\n",
    "    n_jobs=-1,\n",
    "    n_estimators=[64, 80, 96],\n",
    "    max_features=['auto', 'sqrt'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(run_id: str = None):\n",
    "    if run_id is None:\n",
    "        model_path = 'out/pipeline.joblib'\n",
    "    else:\n",
    "        mlflow_client = mlflow.tracking.MlflowClient()\n",
    "        model_path = mlflow_client.download_artifacts(run_id, 'pipeline.joblib')\n",
    "\n",
    "    return joblib.load(model_path)\n",
    "\n",
    "\n",
    "def predict(df: pd.DataFrame, pipeline: Pipeline) -> pd.DataFrame:\n",
    "    x = df.iloc[:, 1:]\n",
    "    y_log1p = pipeline.predict(x)\n",
    "    y = np.expm1(y_log1p)\n",
    "    return pd.DataFrame({\n",
    "        'row_id': df.iloc[:, 0],\n",
    "        'meter_reading': y,\n",
    "    })[['row_id', 'meter_reading']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = load_model()\n",
    "predict(test, p).to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c ashrae-energy-prediction -f submission.csv -m \"weighted average\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(weather_train.iloc[:, 2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train['precip_depth_1_hr'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train.pipe(missing_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
